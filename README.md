# üé¨ Movies Data Engineering Take-Home Test

![PostgreSQL](https://img.shields.io/badge/Database-PostgreSQL-blue?logo=postgresql)
![Python](https://img.shields.io/badge/Language-Python_3.x-yellow?logo=python)
![ETL](https://img.shields.io/badge/Pipeline-ETL-green)
![Status](https://img.shields.io/badge/Status-Completed-success)

---

## üìò Overview

This project demonstrates an end-to-end **data engineering workflow** ‚Äî from **data modeling** to **ETL** and **analytics** ‚Äî using a dataset containing movie information and ratings.

**Objectives**
1. Design a conceptual and logical data model for movies and related entities.  
2. Implement the model in a relational database (PostgreSQL).  
3. Build an ETL pipeline to ingest the provided `movies.csv` dataset.  
4. Write analytical SQL queries (and optional views) to answer business questions.

---

## üß© Project Structure

```plaintext
movies_takehome/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ movies.csv                 # Provided dataset
‚îÇ
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îú‚îÄ‚îÄ ERD_Conceptual.png         # Conceptual data model
‚îÇ   ‚îú‚îÄ‚îÄ ERD_Logical.png            # Logical data model
‚îÇ   ‚îú‚îÄ‚îÄ ERD_Physical.png           # Physical data model
‚îÇ   ‚îî‚îÄ‚îÄ ddl_postgres.sql           # Database schema DDL
‚îÇ
‚îú‚îÄ‚îÄ etl/
‚îÇ   ‚îî‚îÄ‚îÄ etl_load_data.py           # Python ETL script
‚îÇ
‚îú‚îÄ‚îÄ queries/
‚îÇ   ‚îú‚îÄ‚îÄ 4a.sql                     # Business query (4a)
‚îÇ   ‚îú‚îÄ‚îÄ 4b.sql                     # Business query (4b)
‚îÇ   ‚îú‚îÄ‚îÄ 4c.sql                     # Business query (4c)
‚îÇ   ‚îú‚îÄ‚îÄ 4d.sql                     # Business query (4d)
‚îÇ   ‚îî‚îÄ‚îÄ 4e.sql                     # Business query (4e)
‚îÇ
‚îú‚îÄ‚îÄ README.md                      # Documentation
‚îî‚îÄ‚îÄ requirements.txt               # Python dependencies
```


## ‚öôÔ∏è Tech Stack

- **Database:** PostgreSQL (can also use SQL Server / Oracle / etc.)  
- **Programming Language:** Python 3.x  
- **Libraries:** `pandas`, `psycopg2` (or `SQLAlchemy`)  
- **Diagram Tools:** [Visual Paradigm Online](https://online.visual-paradigm.com) & [SQLFlow](https://sqlflow.gudusoft.com)  

> Refer to `requirements.txt` for detailed package.

---

## üß† Data Model Design

### üß© Conceptual Model
The conceptual model defines high-level entities and their relationships:

- üéûÔ∏è **Movie** ‚Üí central entity containing metadata (title, year range, gross, rating, etc.)  
- üé≠ **Genre** ‚Üí multiple genres per movie (many-to-many)  
- üé¨ **Director** ‚Üí one or more directors per movie  
- üë• **Actor** ‚Üí one or more actors per movie  

---

### üß± Logical / Physical Model

#### Example ‚Äî Main Movie Table
```sql
CREATE TABLE movies_app.movie (
    movie_id      TEXT PRIMARY KEY,
    title         TEXT NOT NULL,
    year_start    INT,
    year_end      INT,
    rating        FLOAT,
    gross         NUMERIC(14,2),
    runtime_min   INT,
    description   TEXT,
    raw_row       JSONB,
    created_at    TIMESTAMP DEFAULT now()
);
```

### üìÖ Why year_start and year_end
The year field in the dataset sometimes shows a range (For Series) ‚Äî for example:

`The Walking Dead,(2010‚Äì2022)`

To represent both movies and TV series accurately:

- **year_start** stores the year of release.
- **year_end** stores the final year (nullable for movies).


**üîÑ ETL Flow**
The ETL script (etl_load_data.py) performs the following steps:

**1. Extract**
   
    - Reads movies.csv using pandas.
    - Normalizes text encodings and removes whitespace.

**2. Transform**
   
    - Cleans malformed characters (e.g., √¢‚Ç¨‚Äú ‚Üí ‚Äì).
    - Parses year field into year_start and year_end.
    - Converts numeric columns (gross, runtime) into consistent types.
    - Optionally stores the raw row as JSON for traceability.

**3. Load**

    - Connects to PostgreSQL via psycopg2 or SQLAlchemy.
    - Creates tables if not exist (using create_tables.sql).
    - Loads cleaned records into movies_app.movie.


## üßÆ Analytical Queries

#### File: queries/*

**(4a) ‚Äî Number of unique film titles**
```sql
    SELECT COUNT(DISTINCT title) AS unique_titles FROM movies_app.movie;
```

**(4b) ‚Äî Films starring Lena Headey**
```sql
    SELECT m.title, m.year_start AS year_of_release, m.rating
    FROM movies_app.movie m
    JOIN movies_app.movie_actor ma ON ma.movie_id = m.movie_id
    JOIN movies_app.actor a ON a.actor_id = ma.actor_id
    WHERE LOWER(a.name) = LOWER('Lena Headey')
    ORDER BY m.year_start;
```

**(4c) ‚Äî The name of the director and total gross of the films that have been directed.**
```sql
    SELECT d.name AS director_name, SUM(m.gross) AS total_gross
    FROM movies_app.director d
    JOIN movies_app.movie_director md ON md.director_id = d.director_id
    JOIN movies_app.movie m ON m.movie_id = md.movie_id
    GROUP BY d.name
    ORDER BY total_gross DESC NULLS LAST;
```

**(4d) ‚Äî Top 5 comedy films by gross**
```sql
    SELECT m.title, m.year_start AS year_of_release, m.rating, m.gross
    FROM movies_app.movie m
    JOIN movies_app.movie_genre mg ON mg.movie_id = m.movie_id
    JOIN movies_app.genre g ON g.genre_id = mg.genre_id
    WHERE LOWER(g.name) = LOWER('comedy')
    ORDER BY m.gross DESC NULLS LAST
    LIMIT 5;
```

**(4e) ‚Äî Films directed by Martin Scorsese starring Robert De Niro**
```sql
    SELECT DISTINCT m.title, m.year_start AS year_of_release, m.rating
    FROM movies_app.movie m
    JOIN movies_app.movie_director md ON md.movie_id = m.movie_id
    JOIN movies_app.director d ON d.director_id = md.director_id
    JOIN movies_app.movie_actor ma ON ma.movie_id = m.movie_id
    JOIN movies_app.actor a ON a.actor_id = ma.actor_id
    WHERE LOWER(d.name) = LOWER('Martin Scorsese')
    AND LOWER(a.name) = LOWER('Robert De Niro')
    ORDER BY m.year_start;
```

## üßæ Execution Flow

1. **Model Design** ‚Äî Review the conceptual ERD and generate the SQL schema definitions.  
2. **Database Setup** ‚Äî Deploy a PostgreSQL instance (locally via Docker or in the cloud).  
3. **Schema Initialization** ‚Äî Execute `model/ddl_postgres.sql` to create all required tables.  
4. **Data Ingestion** ‚Äî Run `etl/etl_load_data.py` to extract, transform, and load data from `movies.csv`.  
5. **Data Validation** ‚Äî Verify record counts and inspect sample data using `tests/data_quality_checks.sql`.  
6. **Analytics & Queries** ‚Äî Execute SQL scripts under `queries/` to generate analytical results.  
7. (Optional) Deploy stored procedures/views for recurring reports.


## üë§ Author

**Mikael Andrew**

*`(Created for CAD-IT Technical Take-Home Test)`*

